{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a6a8bd",
   "metadata": {},
   "source": [
    "`Reference`\n",
    "- A survey on Deep Learning Advances on Different 3D DataRepresentations - [pdf](https://arxiv.org/pdf/1808.01462.pdf)\n",
    "- VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition - [pdf](https://www.ri.cmu.edu/pub_files/2015/9/voxnet_maturana_scherer_iros15.pdf)\n",
    "- FusionNet: 3D Object Classification Using MultipleData Representations - [pdf](https://3ddl.cs.princeton.edu/2016/papers/Hegde_Zadeh.pdf)\n",
    "- Uniformizing Techniques to Process CT scans with 3D CNNs for Tuberculosis Prediction - [pdf](https://arxiv.org/abs/2007.13224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292b5f9",
   "metadata": {},
   "source": [
    "# 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d9100",
   "metadata": {},
   "source": [
    "## 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8afb3dcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T05:49:58.004471Z",
     "start_time": "2022-09-02T05:49:54.545644Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import zipfile\n",
    "import random\n",
    "from termcolor import colored\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f728df0",
   "metadata": {},
   "source": [
    "## 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f157370a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T05:49:58.763469Z",
     "start_time": "2022-09-02T05:49:58.751466Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"D:/Dataset/dataset/keras_example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800c4c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T02:11:18.899873Z",
     "start_time": "2022-09-01T02:05:36.685898Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a directory to store the data.\n",
    "os.makedirs(file_path+\"/MosMedData\")\n",
    "\n",
    "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
    "filename = os.path.join(file_path, \"CT-0.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "with zipfile.ZipFile(filename, \"r\") as z_fp:\n",
    "    z_fp.extractall(file_path+\"/MosMedData/\")\n",
    "\n",
    "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
    "filename = os.path.join(file_path, \"CT-23.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "with zipfile.ZipFile(filename, \"r\") as z_fp:\n",
    "    z_fp.extractall(file_path+\"/MosMedData/\")\n",
    "    \n",
    "os.remove(file_path+\"/CT-23.zip\")\n",
    "os.remove(file_path+\"/CT-0.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f58a8",
   "metadata": {},
   "source": [
    "## 데이터 로드, 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caf3c846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T06:35:29.641401Z",
     "start_time": "2022-09-02T06:35:29.625398Z"
    }
   },
   "outputs": [],
   "source": [
    "# nifti 파일 읽기\n",
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    filepath\n",
    "    scan = nib.load(filepath) # Read file\n",
    "    scan = scan.get_fdata() # Get raw data\n",
    "    return scan\n",
    "\n",
    "# 정규화\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "# rotate the volumes by 90 degrees, so the orientation is fixed\n",
    "# scale the HU values to be between 0 and 1.\n",
    "# resize width, height and depth.\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    \n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    \n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    \n",
    "    img = ndimage.rotate(img, 90, reshape=False) # Rotate\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1) # Resize across z-axis\n",
    "    return img\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    volume = read_nifti_file(path) # Read scan\n",
    "    volume = normalize(volume) # Normalize\n",
    "    volume = resize_volume(volume) # Resize width, height and depth\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f8e3d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T06:35:35.421339Z",
     "start_time": "2022-09-02T06:35:35.232445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mCT scans with normal lung tissue\t:\u001b[0m 100\n",
      "\u001b[31mCT scans with abnormal lung tissue\t:\u001b[0m 100\n",
      "\u001b[31mCT scans original image shape\t\t:\u001b[0m (512, 512, 43)\n"
     ]
    }
   ],
   "source": [
    "#no CT-signs of viral pneumonia.\n",
    "normal_scan_paths = [\n",
    "    os.path.join(file_path,\"MosMedData/CT-0\", x)\n",
    "    for x in os.listdir(file_path+\"/MosMedData/CT-0\")\n",
    "]\n",
    "# involvement of lung parenchyma.\n",
    "abnormal_scan_paths = [\n",
    "    os.path.join(file_path, \"MosMedData/CT-23\", x)\n",
    "    for x in os.listdir(file_path+\"/MosMedData/CT-23\")\n",
    "]\n",
    "print(colored(\"CT scans with normal lung tissue\\t:\",\"red\"), str(len(normal_scan_paths)))\n",
    "print(colored(\"CT scans with abnormal lung tissue\\t:\",\"red\"), str(len(abnormal_scan_paths)))\n",
    "\n",
    "print(colored(\"CT scans original image shape\\t\\t:\",\"red\"), read_nifti_file(normal_scan_paths[0]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178b895",
   "metadata": {},
   "source": [
    "## Train/Valid/Test 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a801fbd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-02T06:35:44.486Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(normal_scan_paths)\n",
    "random.shuffle(abnormal_scan_paths)\n",
    "\n",
    "# Read and process the scans.\n",
    "# Each scan is resized across height, width, and depth and rescaled.\n",
    "abnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\n",
    "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bae353",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-02T06:36:44.903Z"
    }
   },
   "outputs": [],
   "source": [
    "# For the CT scans having presence of viral pneumonia\n",
    "# assign 1, for the normal ones assign 0.\n",
    "abnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\n",
    "normal_labels = np.array([0 for _ in range(len(normal_scans))])\n",
    "\n",
    "# Split data in the ratio 70-30 for training and validation.\n",
    "x_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\n",
    "y_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\n",
    "x_val = np.concatenate((abnormal_scans[70:], normal_scans[70:]), axis=0)\n",
    "y_val = np.concatenate((abnormal_labels[70:], normal_labels[70:]), axis=0)\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train.shape[0], x_val.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9dc42c",
   "metadata": {},
   "source": [
    "## 데이터 셋과 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756ffc1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-02T06:36:45.783Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "    def scipy_rotate(volume):\n",
    "        angles = [-20, -10, -5, 5, 10, 20] # define some rotation angles\n",
    "        angle = random.choice(angles) # pick angles at random\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False) # rotate volume\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "    \n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "    volume = rotate(volume)\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc12749",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-02T06:36:46.622Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "batch_size = 1\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ebf3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T03:22:02.421230Z",
     "start_time": "2022-09-01T03:22:02.412179Z"
    }
   },
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ab798",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-02T06:36:47.750Z"
    }
   },
   "outputs": [],
   "source": [
    "data = train_dataset.take(1)\n",
    "images, labels = list(data)[0]\n",
    "images = images.numpy()\n",
    "image = images[0]\n",
    "print(colored(\"Dimension of the CT scan is:\",\"red\"), image.shape)\n",
    "plt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d135ad6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-02T06:36:47.975Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_slices(num_rows, num_columns, width, height, data):\n",
    "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
    "    data = np.rot90(np.array(data))\n",
    "    data = np.transpose(data)\n",
    "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
    "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
    "    heights = [slc[0].shape[0] for slc in data]\n",
    "    widths = [slc.shape[1] for slc in data[0]]\n",
    "    fig_width = 12.0\n",
    "    fig_height = fig_width * sum(heights) / sum(widths)\n",
    "    f, axarr = plt.subplots(\n",
    "        rows_data,\n",
    "        columns_data,\n",
    "        figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={\"height_ratios\": heights},\n",
    "    )\n",
    "    for i in range(rows_data):\n",
    "        for j in range(columns_data):\n",
    "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
    "            axarr[i, j].axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "    plt.show()\n",
    "\n",
    "# 4 rows and 10 columns for 100 slices of the CT scan.\n",
    "print(colored(\"Sample 60 images (100 slices of CT scan)\",\"red\"), image.shape)\n",
    "plot_slices(6, 10, 256, 256, image[:, :, :60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d445d",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a06ba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-02T06:36:49.191Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1), name=\"input\")\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"leaky_relu\", name=\"conv3D_1\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"leaky_relu\", name=\"conv3D_2\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"leaky_relu\", name=\"conv3D_3\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"leaky_relu\", name=\"conv3D_4\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"leaky_relu\", name=\"FC\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Dense(128, activation=\"leaky_relu\", name=\"FC2\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=128, height=128, depth=64)\n",
    "model.summary()\n",
    "utils.plot_model(model, to_file=\"../tmp/3d_CNN.png\",show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b7e8d",
   "metadata": {},
   "source": [
    "# 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc51677",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-09-02T06:36:52.375Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=1000, decay_rate=0.96, staircase=True)\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model/3d_image_classification.h5\", save_best_only=True)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 100\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c791dc",
   "metadata": {},
   "source": [
    "# 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a52d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T05:16:03.462803Z",
     "start_time": "2022-09-01T05:16:03.173733Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"./model/3d_image_classification.h5\")\n",
    "prediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\n",
    "scores = [1 - prediction[0], prediction[0]]\n",
    "\n",
    "class_names = [\"normal\", \"abnormal\"]\n",
    "for score, name in zip(scores, class_names):\n",
    "    print(\n",
    "        \"This model is %.2f percent confident that CT scan is %s\"\n",
    "        % ((100 * score), name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e6fdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T05:16:04.047045Z",
     "start_time": "2022-09-01T05:16:03.869351Z"
    }
   },
   "outputs": [],
   "source": [
    "from Myfunc import show_lcurve\n",
    "show_lcurve([history], [\"\"], [\"b\"],x_itv=10, size=(18,8), lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0cdaf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T05:16:20.560181Z",
     "start_time": "2022-09-01T05:16:19.293591Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "y_pred=model.predict(validation_dataset)\n",
    "y_pred_arg = tf.where(y_pred>=0.5, 1, 0)[:,0]\n",
    "\n",
    "print(colored(\"Test Acc\\t:\",\"red\"),accuracy_score(y_val, y_pred_arg),\"\\n\\n\")\n",
    "print(colored(\"Classfication_report :\\n\", \"red\"), classification_report(y_val, y_pred_arg))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Confusion_matrix\", fontsize=20, color=\"red\")\n",
    "sns.heatmap(confusion_matrix(y_val, y_pred_arg), annot=True, cmap=\"PuBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fca25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
